{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 images belonging to 4 classes.\n",
      "Found 13 images belonging to 4 classes.\n",
      "Treinando o modelo...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 96\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Treinar o modelo\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTreinando o modelo...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Extração de características de todas as imagens do dataset para recomendação\u001b[39;00m\n\u001b[0;32m     99\u001b[0m all_image_paths \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[9], line 62\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_generator, validation_generator)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_model\u001b[39m(model, train_generator, validation_generator):\n\u001b[1;32m---> 62\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32md:\\Users\\carmo\\anaconda3\\envs\\envpy310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Users\\carmo\\anaconda3\\envs\\envpy310\\lib\\site-packages\\keras\\utils\\image_utils.py:414\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    412\u001b[0m     color_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m     )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[0;32m    418\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Diretório onde as imagens estão localizadas\n",
    "dataset_dir = 'dataset'\n",
    "\n",
    "# Função para carregar e pré-processar as imagens\n",
    "def load_data():\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "    # Carregar os dados de treinamento e validação\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "\n",
    "# Função para construir o modelo usando ResNet50\n",
    "def build_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1024, activation='relu'),\n",
    "        layers.Dense(4, activation='softmax')  # 4 classes\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Função para treinar o modelo\n",
    "def train_model(model, train_generator, validation_generator):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "# Função para extrair características de uma imagem usando o modelo treinado\n",
    "def extract_features(model, image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (150, 150))  # Redimensionar para o tamanho da entrada\n",
    "    img = np.expand_dims(img, axis=0) / 255.0  # Normalizar a imagem\n",
    "    features = model.predict(img)\n",
    "    return features.flatten()  # Retornar como vetor de características\n",
    "\n",
    "\n",
    "# Função para realizar a recomendação\n",
    "def recommend_image(model, image_path, feature_array, knn):\n",
    "    features = extract_features(model, image_path)\n",
    "    distances, indices = knn.kneighbors([features])\n",
    "    return indices[0], distances[0]  # Retorna os índices e as distâncias das imagens mais próximas\n",
    "\n",
    "\n",
    "# Função principal de execução\n",
    "def main():\n",
    "    # Carregar dados\n",
    "    train_generator, validation_generator = load_data()\n",
    "\n",
    "    # Construir o modelo\n",
    "    model = build_model()\n",
    "\n",
    "    # Treinar o modelo\n",
    "    print(\"Treinando o modelo...\")\n",
    "    train_model(model, train_generator, validation_generator)\n",
    "\n",
    "    # Extração de características de todas as imagens do dataset para recomendação\n",
    "    all_image_paths = []\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Verificando mais extensões de imagem\n",
    "                all_image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    # Verifica se algum caminho de imagem foi encontrado\n",
    "    if not all_image_paths:\n",
    "        print(f\"Aviso: Nenhum arquivo de imagem encontrado em {dataset_dir}. Por favor, verifique o caminho do diretório e as extensões dos arquivos.\")\n",
    "        return  # Sai do programa se nenhuma imagem for encontrada\n",
    "\n",
    "    feature_list = []\n",
    "    for img_path in all_image_paths:\n",
    "        features = extract_features(model, img_path)\n",
    "        feature_list.append(features)\n",
    "\n",
    "    # Normalizar as características extraídas\n",
    "    feature_array = np.array(feature_list)\n",
    "    feature_array = normalize(feature_array, axis=1, norm='l2')  # Normalização L2 para evitar distâncias inconsistentes\n",
    "\n",
    "    # Treinando o modelo K-NN para encontrar imagens semelhantes\n",
    "    knn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "    knn.fit(feature_array)\n",
    "\n",
    "    # Testando a recomendação\n",
    "    test_image = 'images1.jpg'  # Substitua pelo caminho da imagem de teste\n",
    "    indices, distances = recommend_image(model, test_image, feature_array, knn)\n",
    "\n",
    "    # Exibindo as imagens recomendadas\n",
    "    print(\"Imagens recomendadas:\")\n",
    "    for i, idx in enumerate(indices):\n",
    "        recommended_img_path = all_image_paths[idx]\n",
    "        print(f\"{i+1}. {recommended_img_path} (Distância: {distances[i]:.4f})\")\n",
    "        img = cv2.imread(recommended_img_path)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow version: 11.1.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(\"Pillow version:\", Image.__version__)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
